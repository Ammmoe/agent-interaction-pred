{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c12c7c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import joblib\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from pathlib import Path\n",
    "from data.data_loader import DroneGraphDataset\n",
    "from models.pretrained_model_loader import load_pretrained_traj_model, extract_context_embeddings, extract_decoder_embeddings\n",
    "from models.tgn import DroneRelationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cb26754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Skipping] Flight 0, timestep 33.567 has 4 drones\n",
      "[Skipping] Flight 2, timestep 31.267 has 1 drones\n",
      "[Skipping] Flight 4, timestep 33.2 has 1 drones\n",
      "[Skipping] Flight 5, timestep 33.567 has 2 drones\n",
      "[Skipping] Flight 6, timestep 33.467 has 4 drones\n",
      "[Skipping] Flight 7, timestep 29.233 has 3 drones\n",
      "[Skipping] Flight 8, timestep 33.1 has 2 drones\n",
      "[Skipping] Flight 9, timestep 27.367 has 5 drones\n",
      "[Skipping] Flight 10, timestep 28.233 has 5 drones\n",
      "[Skipping] Flight 11, timestep 26.7 has 2 drones\n",
      "[Skipping] Flight 12, timestep 35.067 has 3 drones\n",
      "[Skipping] Flight 14, timestep 33.667 has 5 drones\n",
      "[Skipping] Flight 15, timestep 30.933 has 1 drones\n",
      "[Skipping] Flight 16, timestep 31.533 has 2 drones\n",
      "[Skipping] Flight 17, timestep 28.0 has 1 drones\n",
      "[Skipping] Flight 18, timestep 31.133 has 1 drones\n",
      "[Skipping] Flight 20, timestep 26.9 has 4 drones\n",
      "[Skipping] Flight 21, timestep 32.833 has 5 drones\n",
      "[Skipping] Flight 22, timestep 32.667 has 1 drones\n",
      "[Skipping] Flight 23, timestep 29.4 has 2 drones\n",
      "[Skipping] Flight 24, timestep 36.9 has 1 drones\n",
      "[Skipping] Flight 25, timestep 34.333 has 4 drones\n",
      "[Skipping] Flight 26, timestep 29.0 has 1 drones\n",
      "[Skipping] Flight 27, timestep 34.067 has 5 drones\n",
      "[Skipping] Flight 28, timestep 27.467 has 2 drones\n",
      "[Skipping] Flight 29, timestep 29.9 has 4 drones\n",
      "torch.Size([50, 6, 4])\n",
      "torch.Size([6, 4])\n",
      "torch.Size([9, 2])\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "dataset = DroneGraphDataset(\n",
    "    trajectory_csv='data/drone_states.csv',\n",
    "    relationship_csv='data/drone_relations.csv',\n",
    "    lookback=50,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "sample = dataset[0]\n",
    "print(sample['context_window'].shape)    # [50, num_drones, 4]\n",
    "print(sample['current_features'].shape)  # [num_drones, 4]\n",
    "print(sample['relationships'].shape)     # [num_pairs, 2]\n",
    "# print(sample['labels'].shape)            # [num_pairs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0beb0f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context embeddings shape: torch.Size([6, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator MinMaxScaler from version 1.7.2 when using version 1.5.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "experiment_dir = Path(\"experiments/20251015_134311\")\n",
    "\n",
    "# Load model + config\n",
    "model, config = load_pretrained_traj_model(experiment_dir, device)\n",
    "\n",
    "# Load scalers\n",
    "scaler_X = joblib.load(experiment_dir / \"scaler_X.pkl\")\n",
    "\n",
    "# Dummy trajectory data (replace with your actual drone trajectory segment)\n",
    "dummy_data = np.random.rand(100, 6 * 3).astype(np.float32)  # 100 timesteps, 6 drones, xyz\n",
    "\n",
    "# Extract embeddings\n",
    "context_emb = extract_context_embeddings(\n",
    "    model,\n",
    "    traj_data=dummy_data,\n",
    "    scaler_X=scaler_X,\n",
    "    lookback=config[\"LOOK_BACK\"],\n",
    "    features_per_agent=3,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "print(\"Context embeddings shape:\", context_emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7697aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "\n",
    "flight_ids = dataset.flights\n",
    "num_train = int(0.8 * len(flight_ids))\n",
    "train_flights = flight_ids[:num_train]\n",
    "test_flights = flight_ids[num_train:]\n",
    "\n",
    "train_indices = [i for i, (fid, _) in enumerate(dataset.valid_indices) if fid in train_flights]\n",
    "test_indices = [i for i, (fid, _) in enumerate(dataset.valid_indices) if fid in test_flights]\n",
    "\n",
    "train_ds = Subset(dataset, train_indices)\n",
    "test_ds = Subset(dataset, test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1256995c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_pairs(relationships, labels, max_neg_per_pos=1):\n",
    "    \"\"\"\n",
    "    Undersample negative pairs so the ratio between negatives and positives\n",
    "    is roughly `max_neg_per_pos` : 1.\n",
    "    \"\"\"\n",
    "    pos_mask = labels == 1\n",
    "    neg_mask = labels == 0\n",
    "\n",
    "    pos_indices = torch.nonzero(pos_mask).squeeze(1)\n",
    "    neg_indices = torch.nonzero(neg_mask).squeeze(1)\n",
    "\n",
    "    num_pos = len(pos_indices)\n",
    "    num_neg = len(neg_indices)\n",
    "    if num_pos == 0 or num_neg == 0:\n",
    "        return relationships, labels  # skip balancing if only one class\n",
    "\n",
    "    # Sample negatives\n",
    "    num_keep_neg = min(num_neg, num_pos * max_neg_per_pos)\n",
    "    sampled_neg_indices = neg_indices[torch.randperm(num_neg)[:num_keep_neg]]\n",
    "\n",
    "    # Combine and shuffle\n",
    "    keep_indices = torch.cat([pos_indices, sampled_neg_indices])\n",
    "    keep_indices = keep_indices[torch.randperm(len(keep_indices))]\n",
    "\n",
    "    return relationships[keep_indices], labels[keep_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42f1c64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, criterion, scaler_X, pretrained_model, config):\n",
    "    model.train()\n",
    "    pretrained_model.train()\n",
    "    total_loss = 0\n",
    "    for batch in loader:\n",
    "        context_window = batch[\"context_window\"].squeeze(0).to(device)  # [50, num_drones, 4]\n",
    "        current_features = batch[\"current_features\"].squeeze(0).to('cpu')\n",
    "        relationships = batch[\"relationships\"].squeeze(0).to('cpu')\n",
    "        # labels = batch[\"labels\"].squeeze(0).float().to('cpu')\n",
    "        \n",
    "        # --- New: target indices per friendly drone ---\n",
    "        target_indices = batch[\"target_indices\"].squeeze(0).to(device)  # [num_friendly]\n",
    "\n",
    "        num_friendly = batch[\"num_friendly\"]\n",
    "        num_unauth = batch[\"num_unauth\"]\n",
    "\n",
    "        # relationships, labels = balance_pairs(relationships, labels, max_neg_per_pos=1)\n",
    "        relationships = batch[\"relationships\"].squeeze(0).to(device)\n",
    "        \n",
    "        # Extract context embeddings from pretrained model\n",
    "        context_emb = extract_decoder_embeddings(\n",
    "            pretrained_model,\n",
    "            traj_data=context_window[:, :, :3].reshape(50, -1),\n",
    "            scaler_X=scaler_X,\n",
    "            lookback=config[\"LOOK_BACK\"],\n",
    "            features_per_agent=3,\n",
    "            device='cpu',\n",
    "        )\n",
    "        \n",
    "        # preds = model(current_features, context_emb, relationships)\n",
    "        # loss = criterion(preds, labels)\n",
    "        \n",
    "        probs, logits = model(current_features, context_emb, relationships, num_friendly, num_unauth)\n",
    "        loss = criterion(logits, target_indices)  # logits: [num_friendly, num_unauth]\n",
    "        \n",
    "        # custom weighting\n",
    "        # weights = torch.where(labels == 1, 2.0, 1.0)  # higher weight for 1s\n",
    "        # loss = (weights * loss).mean()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf74c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_score, recall_score, f1_score\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, scaler_X, pretrained_model, config, show_confusion=True):\n",
    "    model.eval()\n",
    "    pretrained_model.eval()\n",
    "    preds_all, labels_all = [], []\n",
    "\n",
    "    for batch in loader:\n",
    "        context_window = batch[\"context_window\"].squeeze(0).cpu().numpy()\n",
    "        current_features = batch[\"current_features\"].squeeze(0).to(\"cpu\")\n",
    "        # relationships = batch[\"relationships\"].squeeze(0).to(\"cpu\")\n",
    "        # labels = batch[\"labels\"].squeeze(0).float().to(\"cpu\")\n",
    "        relationships = batch[\"relationships\"].squeeze(0).to(device)\n",
    "        \n",
    "        target_indices = batch[\"target_indices\"].squeeze(0).to(\"cpu\")\n",
    "        num_friendly = batch[\"num_friendly\"]\n",
    "        num_unauth = batch[\"num_unauth\"]\n",
    "        \n",
    "        context_emb = extract_decoder_embeddings(\n",
    "            pretrained_model,\n",
    "            traj_data=context_window[:, :, :3].reshape(50, -1),\n",
    "            scaler_X=scaler_X,\n",
    "            lookback=config[\"LOOK_BACK\"],\n",
    "            features_per_agent=3,\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "        # preds = model(current_features, context_emb, relationships)\n",
    "        # preds = torch.sigmoid(preds)  # Apply sigmoid to get probabilities\n",
    "        \n",
    "        probs, logits = model(current_features, context_emb, relationships, num_friendly, num_unauth)\n",
    "        \n",
    "        # Predicted unauthorized drone per friendly\n",
    "        pred_indices = torch.argmax(probs, dim=1)\n",
    "\n",
    "        preds_all.append(pred_indices)\n",
    "        labels_all.append(target_indices)\n",
    "\n",
    "    preds_all = torch.cat(preds_all)\n",
    "    labels_all = torch.cat(labels_all)\n",
    "    \n",
    "    print(preds_all.min().item(), preds_all.max().item())\n",
    "    print(labels_all.min().item(), labels_all.max().item())\n",
    "\n",
    "    # # Binary predictions\n",
    "    # y_true = labels_all.cpu().numpy().astype(int)\n",
    "    # y_pred = (preds_all.cpu().numpy() > 0.5).astype(int)\n",
    "\n",
    "    # # Compute accuracy\n",
    "    # acc = (y_true == y_pred).mean().item()\n",
    "    \n",
    "    # Compute accuracy\n",
    "    acc = (preds_all == labels_all).float().mean().item()\n",
    "    print(f\"Accuracy: {acc:.3f}\")\n",
    "\n",
    "    # if show_confusion:\n",
    "    #     # Compute confusion matrix\n",
    "    #     cm = confusion_matrix(y_true, y_pred)\n",
    "    #     disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"0\", \"1\"])\n",
    "    #     disp.plot(cmap=\"Blues\", colorbar=False)\n",
    "    #     plt.title(\"Confusion Matrix\")\n",
    "    #     plt.show()\n",
    "\n",
    "    #     # Optional: print precision/recall/F1\n",
    "    #     precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    #     recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    #     f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    #     print(f\"Precision: {precision:.3f}, Recall: {recall:.3f}, F1: {f1:.3f}\")\n",
    "    \n",
    "    if show_confusion:\n",
    "        y_true = labels_all.cpu().numpy()\n",
    "        y_pred = preds_all.cpu().numpy()\n",
    "        cm = confusion_matrix(y_true, y_pred, labels=list(range(num_unauth)))\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap=\"Blues\", colorbar=False)\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.show()\n",
    "\n",
    "        # Optional: print precision/recall/F1 (micro-averaged)\n",
    "        precision = precision_score(y_true, y_pred, average=\"micro\", zero_division=0)\n",
    "        recall = recall_score(y_true, y_pred, average=\"micro\", zero_division=0)\n",
    "        f1 = f1_score(y_true, y_pred, average=\"micro\", zero_division=0)\n",
    "        print(f\"Precision: {precision:.3f}, Recall: {recall:.3f}, F1: {f1:.3f}\")\n",
    "        \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c40a725",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator MinMaxScaler from version 1.7.2 when using version 1.5.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (9x256 and 128x64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m     25\u001b[0m     loss \u001b[38;5;241m=\u001b[39m train_epoch(relation_model, train_ds, optimizer, criterion, scaler_X, model_traj, config)\n\u001b[0;32m---> 26\u001b[0m     acc \u001b[38;5;241m=\u001b[39m evaluate(relation_model, test_ds, scaler_X, model_traj, config)\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Loss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Test Acc=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[0;32mIn[7], line 33\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(model, loader, scaler_X, pretrained_model, config, show_confusion)\u001b[0m\n\u001b[1;32m     21\u001b[0m context_emb \u001b[38;5;241m=\u001b[39m extract_context_embeddings(\n\u001b[1;32m     22\u001b[0m     pretrained_model,\n\u001b[1;32m     23\u001b[0m     traj_data\u001b[38;5;241m=\u001b[39mcontext_window[:, :, :\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m     28\u001b[0m )\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# preds = model(current_features, context_emb, relationships)\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# preds = torch.sigmoid(preds)  # Apply sigmoid to get probabilities\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m probs, logits \u001b[38;5;241m=\u001b[39m model(current_features, context_emb, relationships, num_friendly, num_unauth)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Predicted unauthorized drone per friendly\u001b[39;00m\n\u001b[1;32m     36\u001b[0m pred_indices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(probs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/Temasek Labs/Agent_Interaction/models/tgn.py:175\u001b[0m, in \u001b[0;36mDroneRelationModel.forward\u001b[0;34m(self, current_features, decoder_outputs, relationships, num_friendly, num_unauth)\u001b[0m\n\u001b[1;32m    172\u001b[0m pair_emb \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([src, dst], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# [num_pairs, 2*decoder_hidden_dim]\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# Compute logits per pair\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelation_head(pair_emb)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# [num_pairs]\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# Reshape to [num_friendly, num_unauth] for softmax\u001b[39;00m\n\u001b[1;32m    178\u001b[0m logits \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39mview(num_friendly, num_unauth)   \u001b[38;5;66;03m# [num_friendly, num_unauth]\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/container.py:240\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 240\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (9x256 and 128x64)"
     ]
    }
   ],
   "source": [
    "# Load pretrained trajectory model\n",
    "model_traj, config = load_pretrained_traj_model(experiment_dir, device)\n",
    "scaler_X = joblib.load(experiment_dir / \"scaler_X.pkl\")\n",
    "\n",
    "# Initialize new relation model\n",
    "relation_model = DroneRelationModel(context_dim=model_traj.dec_hidden_size).to(device)\n",
    "# relation_model = DroneRelationModel(\n",
    "#     context_dim=model_traj.enc_hidden_size * 2,\n",
    "# ).to(device)\n",
    "\n",
    "# optimizer = optim.Adam(relation_model.parameters(), lr=1e-3)\n",
    "optimizer = optim.Adam([\n",
    "    {\"params\": relation_model.parameters(), \"lr\": 1e-4},\n",
    "    {\"params\": model_traj.parameters(), \"lr\": 1e-4},\n",
    "])\n",
    "# pos_weight = torch.tensor([2.0], device=device)\n",
    "# criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# criterion = nn.BCELoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(10):\n",
    "    loss = train_epoch(relation_model, train_ds, optimizer, criterion, scaler_X, model_traj, config)\n",
    "    acc = evaluate(relation_model, test_ds, scaler_X, model_traj, config)\n",
    "    print(f\"Epoch {epoch+1}: Loss={loss:.4f}, Test Acc={acc:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
