{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12c7c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import joblib\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from pathlib import Path\n",
    "from data.data_loader import DroneGraphDataset\n",
    "from models.pretrained_model_loader import load_pretrained_traj_model, extract_context_embeddings, extract_decoder_embeddings\n",
    "from models.tgn import DroneRelationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb26754",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "dataset = DroneGraphDataset(\n",
    "    trajectory_csv='data/drone_states.csv',\n",
    "    relationship_csv='data/drone_relations.csv',\n",
    "    lookback=50,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "sample = dataset[0]\n",
    "print(sample['context_window'].shape)    # [50, num_drones, 4]\n",
    "print(sample['current_features'].shape)  # [num_drones, 4]\n",
    "print(sample['relationships'].shape)     # [num_pairs, 2]\n",
    "print(sample['labels'].shape)            # [num_pairs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0beb0f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "experiment_dir = Path(\"experiments/20251015_134311\")\n",
    "\n",
    "# Load model + config\n",
    "model, config = load_pretrained_traj_model(experiment_dir, device)\n",
    "\n",
    "# Load scalers\n",
    "scaler_X = joblib.load(experiment_dir / \"scaler_X.pkl\")\n",
    "\n",
    "# Dummy trajectory data (replace with your actual drone trajectory segment)\n",
    "dummy_data = np.random.rand(100, 6 * 3).astype(np.float32)  # 100 timesteps, 6 drones, xyz\n",
    "\n",
    "# Extract embeddings\n",
    "context_emb = extract_context_embeddings(\n",
    "    model,\n",
    "    traj_data=dummy_data,\n",
    "    scaler_X=scaler_X,\n",
    "    lookback=config[\"LOOK_BACK\"],\n",
    "    features_per_agent=3,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "print(\"Context embeddings shape:\", context_emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7697aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "\n",
    "flight_ids = dataset.flights\n",
    "num_train = int(0.8 * len(flight_ids))\n",
    "train_flights = flight_ids[:num_train]\n",
    "test_flights = flight_ids[num_train:]\n",
    "\n",
    "train_indices = [i for i, (fid, _) in enumerate(dataset.valid_indices) if fid in train_flights]\n",
    "test_indices = [i for i, (fid, _) in enumerate(dataset.valid_indices) if fid in test_flights]\n",
    "\n",
    "train_ds = Subset(dataset, train_indices)\n",
    "test_ds = Subset(dataset, test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1256995c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_pairs(relationships, labels, max_neg_per_pos=1):\n",
    "    \"\"\"\n",
    "    Undersample negative pairs so the ratio between negatives and positives\n",
    "    is roughly `max_neg_per_pos` : 1.\n",
    "    \"\"\"\n",
    "    pos_mask = labels == 1\n",
    "    neg_mask = labels == 0\n",
    "\n",
    "    pos_indices = torch.nonzero(pos_mask).squeeze(1)\n",
    "    neg_indices = torch.nonzero(neg_mask).squeeze(1)\n",
    "\n",
    "    num_pos = len(pos_indices)\n",
    "    num_neg = len(neg_indices)\n",
    "    if num_pos == 0 or num_neg == 0:\n",
    "        return relationships, labels  # skip balancing if only one class\n",
    "\n",
    "    # Sample negatives\n",
    "    num_keep_neg = min(num_neg, num_pos * max_neg_per_pos)\n",
    "    sampled_neg_indices = neg_indices[torch.randperm(num_neg)[:num_keep_neg]]\n",
    "\n",
    "    # Combine and shuffle\n",
    "    keep_indices = torch.cat([pos_indices, sampled_neg_indices])\n",
    "    keep_indices = keep_indices[torch.randperm(len(keep_indices))]\n",
    "\n",
    "    return relationships[keep_indices], labels[keep_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f1c64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, criterion, scaler_X, pretrained_model, config):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in loader:\n",
    "        context_window = batch[\"context_window\"].squeeze(0).cpu().numpy()  # [50, num_drones, 4]\n",
    "        current_features = batch[\"current_features\"].squeeze(0).to('cpu')\n",
    "        relationships = batch[\"relationships\"].squeeze(0).to('cpu')\n",
    "        labels = batch[\"labels\"].squeeze(0).float().to('cpu')\n",
    "\n",
    "        relationships, labels = balance_pairs(relationships, labels, max_neg_per_pos=1)\n",
    "        \n",
    "        # Extract context embeddings from pretrained model\n",
    "        context_emb = extract_decoder_embeddings(\n",
    "            pretrained_model,\n",
    "            traj_data=context_window[:, :, :3].reshape(50, -1),\n",
    "            scaler_X=scaler_X,\n",
    "            lookback=config[\"LOOK_BACK\"],\n",
    "            features_per_agent=3,\n",
    "            device='cpu',\n",
    "        )\n",
    "        \n",
    "        preds = model(current_features, context_emb, relationships)\n",
    "        loss = criterion(preds, labels)\n",
    "        \n",
    "        # custom weighting\n",
    "        # weights = torch.where(labels == 1, 2.0, 1.0)  # higher weight for 1s\n",
    "        # loss = (weights * loss).mean()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf74c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_score, recall_score, f1_score\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, scaler_X, pretrained_model, config, show_confusion=True):\n",
    "    model.eval()\n",
    "    preds_all, labels_all = [], []\n",
    "\n",
    "    for batch in loader:\n",
    "        context_window = batch[\"context_window\"].squeeze(0).cpu().numpy()\n",
    "        current_features = batch[\"current_features\"].squeeze(0).to(\"cpu\")\n",
    "        relationships = batch[\"relationships\"].squeeze(0).to(\"cpu\")\n",
    "        labels = batch[\"labels\"].squeeze(0).float().to(\"cpu\")\n",
    "        \n",
    "        context_emb = extract_decoder_embeddings(\n",
    "            pretrained_model,\n",
    "            traj_data=context_window[:, :, :3].reshape(50, -1),\n",
    "            scaler_X=scaler_X,\n",
    "            lookback=config[\"LOOK_BACK\"],\n",
    "            features_per_agent=3,\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "        preds = model(current_features, context_emb, relationships)\n",
    "        # preds = torch.sigmoid(preds)  # Apply sigmoid to get probabilities\n",
    "        preds_all.append(preds)\n",
    "        labels_all.append(labels)\n",
    "\n",
    "    preds_all = torch.cat(preds_all)\n",
    "    labels_all = torch.cat(labels_all)\n",
    "    \n",
    "    print(preds_all.min().item(), preds_all.max().item())\n",
    "\n",
    "    # Binary predictions\n",
    "    y_true = labels_all.cpu().numpy().astype(int)\n",
    "    y_pred = (preds_all.cpu().numpy() > 0.5).astype(int)\n",
    "\n",
    "    # Compute accuracy\n",
    "    acc = (y_true == y_pred).mean().item()\n",
    "\n",
    "    if show_confusion:\n",
    "        # Compute confusion matrix\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"0\", \"1\"])\n",
    "        disp.plot(cmap=\"Blues\", colorbar=False)\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.show()\n",
    "\n",
    "        # Optional: print precision/recall/F1\n",
    "        precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "        recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "        print(f\"Precision: {precision:.3f}, Recall: {recall:.3f}, F1: {f1:.3f}\")\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c40a725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained trajectory model\n",
    "model_traj, config = load_pretrained_traj_model(experiment_dir, device)\n",
    "scaler_X = joblib.load(experiment_dir / \"scaler_X.pkl\")\n",
    "\n",
    "# Initialize new relation model\n",
    "relation_model = DroneRelationModel(context_dim=model_traj.dec_hidden_size).to(device)\n",
    "\n",
    "optimizer = optim.Adam(relation_model.parameters(), lr=1e-3)\n",
    "# pos_weight = torch.tensor([2.0], device=device)\n",
    "# criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(10):\n",
    "    loss = train_epoch(relation_model, train_ds, optimizer, criterion, scaler_X, model_traj, config)\n",
    "    acc = evaluate(relation_model, test_ds, scaler_X, model_traj, config)\n",
    "    print(f\"Epoch {epoch+1}: Loss={loss:.4f}, Test Acc={acc:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
