{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c12c7c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import joblib\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from pathlib import Path\n",
    "from data.data_loader import DroneGraphDataset\n",
    "from models.pretrained_model_loader import load_pretrained_traj_model, extract_context_embeddings, extract_decoder_embeddings\n",
    "from models.tgn import DroneRelationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cb26754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Skipping] Flight 0, timestep 33.567 has 4 drones\n",
      "[Skipping] Flight 2, timestep 31.267 has 1 drones\n",
      "[Skipping] Flight 4, timestep 33.2 has 1 drones\n",
      "[Skipping] Flight 5, timestep 33.567 has 2 drones\n",
      "[Skipping] Flight 6, timestep 33.467 has 4 drones\n",
      "[Skipping] Flight 7, timestep 29.233 has 3 drones\n",
      "[Skipping] Flight 8, timestep 33.1 has 2 drones\n",
      "[Skipping] Flight 9, timestep 27.367 has 5 drones\n",
      "[Skipping] Flight 10, timestep 28.233 has 5 drones\n",
      "[Skipping] Flight 11, timestep 26.7 has 2 drones\n",
      "[Skipping] Flight 12, timestep 35.067 has 3 drones\n",
      "[Skipping] Flight 14, timestep 33.667 has 5 drones\n",
      "[Skipping] Flight 15, timestep 30.933 has 1 drones\n",
      "[Skipping] Flight 16, timestep 31.533 has 2 drones\n",
      "[Skipping] Flight 17, timestep 28.0 has 1 drones\n",
      "[Skipping] Flight 18, timestep 31.133 has 1 drones\n",
      "[Skipping] Flight 20, timestep 26.9 has 4 drones\n",
      "[Skipping] Flight 21, timestep 32.833 has 5 drones\n",
      "[Skipping] Flight 22, timestep 32.667 has 1 drones\n",
      "[Skipping] Flight 23, timestep 29.4 has 2 drones\n",
      "[Skipping] Flight 24, timestep 36.9 has 1 drones\n",
      "[Skipping] Flight 25, timestep 34.333 has 4 drones\n",
      "[Skipping] Flight 26, timestep 29.0 has 1 drones\n",
      "[Skipping] Flight 27, timestep 34.067 has 5 drones\n",
      "[Skipping] Flight 28, timestep 27.467 has 2 drones\n",
      "[Skipping] Flight 29, timestep 29.9 has 4 drones\n",
      "torch.Size([50, 6, 4])\n",
      "torch.Size([6, 4])\n",
      "torch.Size([9, 2])\n",
      "torch.Size([9])\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "dataset = DroneGraphDataset(\n",
    "    trajectory_csv='data/drone_states.csv',\n",
    "    relationship_csv='data/drone_relations.csv',\n",
    "    lookback=50,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "sample = dataset[0]\n",
    "print(sample['context_window'].shape)    # [50, num_drones, 4]\n",
    "print(sample['current_features'].shape)  # [num_drones, 4]\n",
    "print(sample['relationships'].shape)     # [num_pairs, 2]\n",
    "print(sample['labels'].shape)            # [num_pairs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0beb0f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context embeddings shape: torch.Size([6, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator MinMaxScaler from version 1.7.2 when using version 1.5.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "experiment_dir = Path(\"experiments/20251015_134311\")\n",
    "\n",
    "# Load model + config\n",
    "model, config = load_pretrained_traj_model(experiment_dir, device)\n",
    "\n",
    "# Load scalers\n",
    "scaler_X = joblib.load(experiment_dir / \"scaler_X.pkl\")\n",
    "\n",
    "# Dummy trajectory data (replace with your actual drone trajectory segment)\n",
    "dummy_data = np.random.rand(100, 6 * 3).astype(np.float32)  # 100 timesteps, 6 drones, xyz\n",
    "\n",
    "# Extract embeddings\n",
    "context_emb = extract_context_embeddings(\n",
    "    model,\n",
    "    traj_data=dummy_data,\n",
    "    scaler_X=scaler_X,\n",
    "    lookback=config[\"LOOK_BACK\"],\n",
    "    features_per_agent=3,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "print(\"Context embeddings shape:\", context_emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7697aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "\n",
    "flight_ids = dataset.flights\n",
    "num_train = int(0.8 * len(flight_ids))\n",
    "train_flights = flight_ids[:num_train]\n",
    "test_flights = flight_ids[num_train:]\n",
    "\n",
    "train_indices = [i for i, (fid, _) in enumerate(dataset.valid_indices) if fid in train_flights]\n",
    "test_indices = [i for i, (fid, _) in enumerate(dataset.valid_indices) if fid in test_flights]\n",
    "\n",
    "train_ds = Subset(dataset, train_indices)\n",
    "test_ds = Subset(dataset, test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42f1c64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, criterion, scaler_X, pretrained_model, config):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in loader:\n",
    "        context_window = batch[\"context_window\"].squeeze(0).cpu().numpy()  # [50, num_drones, 4]\n",
    "        current_features = batch[\"current_features\"].squeeze(0).to('cpu')\n",
    "        relationships = batch[\"relationships\"].squeeze(0).to('cpu')\n",
    "        labels = batch[\"labels\"].squeeze(0).float().to('cpu')\n",
    "\n",
    "        # Extract context embeddings from pretrained model\n",
    "        context_emb = extract_decoder_embeddings(\n",
    "            pretrained_model,\n",
    "            traj_data=context_window[:, :, :3].reshape(50, -1),\n",
    "            scaler_X=scaler_X,\n",
    "            lookback=config[\"LOOK_BACK\"],\n",
    "            features_per_agent=3,\n",
    "            device='cpu',\n",
    "        )\n",
    "\n",
    "        preds = model(current_features, context_emb, relationships)\n",
    "        loss = criterion(preds, labels)\n",
    "        \n",
    "        # custom weighting\n",
    "        # weights = torch.where(labels == 1, 2.0, 1.0)  # higher weight for 1s\n",
    "        # loss = (weights * loss).mean()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccf74c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_score, recall_score, f1_score\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, scaler_X, pretrained_model, config, show_confusion=True):\n",
    "    model.eval()\n",
    "    preds_all, labels_all = [], []\n",
    "\n",
    "    for batch in loader:\n",
    "        context_window = batch[\"context_window\"].squeeze(0).cpu().numpy()\n",
    "        current_features = batch[\"current_features\"].squeeze(0).to(\"cpu\")\n",
    "        relationships = batch[\"relationships\"].squeeze(0).to(\"cpu\")\n",
    "        labels = batch[\"labels\"].squeeze(0).float().to(\"cpu\")\n",
    "\n",
    "        context_emb = extract_decoder_embeddings(\n",
    "            pretrained_model,\n",
    "            traj_data=context_window[:, :, :3].reshape(50, -1),\n",
    "            scaler_X=scaler_X,\n",
    "            lookback=config[\"LOOK_BACK\"],\n",
    "            features_per_agent=3,\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "        preds = model(current_features, context_emb, relationships)\n",
    "        preds_all.append(preds)\n",
    "        labels_all.append(labels)\n",
    "\n",
    "    preds_all = torch.cat(preds_all)\n",
    "    labels_all = torch.cat(labels_all)\n",
    "\n",
    "    # Binary predictions\n",
    "    y_true = labels_all.cpu().numpy().astype(int)\n",
    "    y_pred = (preds_all.cpu().numpy() > 0.5).astype(int)\n",
    "\n",
    "    # Compute accuracy\n",
    "    acc = (y_true == y_pred).mean().item()\n",
    "\n",
    "    if show_confusion:\n",
    "        # Compute confusion matrix\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"0\", \"1\"])\n",
    "        disp.plot(cmap=\"Blues\", colorbar=False)\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.show()\n",
    "\n",
    "        # Optional: print precision/recall/F1\n",
    "        precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "        recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "        print(f\"Precision: {precision:.3f}, Recall: {recall:.3f}, F1: {f1:.3f}\")\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c40a725",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator MinMaxScaler from version 1.7.2 when using version 1.5.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.000, Recall: 0.000, F1: 0.000\n",
      "Epoch 1: Loss=0.6365, Test Acc=0.667\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Training loop\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m---> 13\u001b[0m     loss \u001b[38;5;241m=\u001b[39m train_epoch(relation_model, train_ds, optimizer, criterion, scaler_X, model_traj, config)\n\u001b[1;32m     14\u001b[0m     acc \u001b[38;5;241m=\u001b[39m evaluate(relation_model, test_ds, scaler_X, model_traj, config)\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Loss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Test Acc=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 11\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, loader, optimizer, criterion, scaler_X, pretrained_model, config)\u001b[0m\n\u001b[1;32m      8\u001b[0m labels \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Extract context embeddings from pretrained model\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m context_emb \u001b[38;5;241m=\u001b[39m extract_decoder_embeddings(\n\u001b[1;32m     12\u001b[0m     pretrained_model,\n\u001b[1;32m     13\u001b[0m     traj_data\u001b[38;5;241m=\u001b[39mcontext_window[:, :, :\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     14\u001b[0m     scaler_X\u001b[38;5;241m=\u001b[39mscaler_X,\n\u001b[1;32m     15\u001b[0m     lookback\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLOOK_BACK\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     16\u001b[0m     features_per_agent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m     17\u001b[0m     device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     20\u001b[0m preds \u001b[38;5;241m=\u001b[39m model(current_features, context_emb, relationships)\n\u001b[1;32m     21\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(preds, labels)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Documents/Temasek Labs/Agent_Interaction/models/pretrained_model_loader.py:116\u001b[0m, in \u001b[0;36mextract_decoder_embeddings\u001b[0;34m(model, traj_data, scaler_X, lookback, features_per_agent, device)\u001b[0m\n\u001b[1;32m    113\u001b[0m agent_embeddings \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m agent_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_agents):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# Encoder\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m     enc_output, hidden \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencoder(src_agents[agent_idx])\n\u001b[1;32m    117\u001b[0m     num_directions \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    118\u001b[0m     hidden_cat \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    119\u001b[0m         torch\u001b[38;5;241m.\u001b[39mcat([hidden[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m], hidden[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    120\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m num_directions \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    121\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m hidden[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    122\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/rnn.py:1393\u001b[0m, in \u001b[0;36mGRU.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1391\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_forward_args(\u001b[38;5;28minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m   1392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1393\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mgru(\n\u001b[1;32m   1394\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   1395\u001b[0m         hx,\n\u001b[1;32m   1396\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   1397\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m   1398\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers,\n\u001b[1;32m   1399\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout,\n\u001b[1;32m   1400\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining,\n\u001b[1;32m   1401\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional,\n\u001b[1;32m   1402\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first,\n\u001b[1;32m   1403\u001b[0m     )\n\u001b[1;32m   1404\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1405\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mgru(\n\u001b[1;32m   1406\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   1407\u001b[0m         batch_sizes,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1414\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional,\n\u001b[1;32m   1415\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load pretrained trajectory model\n",
    "model_traj, config = load_pretrained_traj_model(experiment_dir, device)\n",
    "scaler_X = joblib.load(experiment_dir / \"scaler_X.pkl\")\n",
    "\n",
    "# Initialize new relation model\n",
    "relation_model = DroneRelationModel(context_dim=model_traj.dec_hidden_size).to(device)\n",
    "\n",
    "optimizer = optim.Adam(relation_model.parameters(), lr=1e-3)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(10):\n",
    "    loss = train_epoch(relation_model, train_ds, optimizer, criterion, scaler_X, model_traj, config)\n",
    "    acc = evaluate(relation_model, test_ds, scaler_X, model_traj, config)\n",
    "    print(f\"Epoch {epoch+1}: Loss={loss:.4f}, Test Acc={acc:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
